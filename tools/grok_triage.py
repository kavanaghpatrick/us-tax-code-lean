#!/usr/bin/env python3
"""
Grok-Assisted Triage System for Aristotle Resubmissions

This script:
1. Auto-categorizes all section files
2. Uses Grok API for ambiguous cases to determine best action
3. Builds a prioritized resubmission queue

Categories:
- COMPLETE: Has real implementation, no issues
- SORRY: Has implementation but needs proof completion
- STUB: Only boilerplate, needs full Aristotle processing
- QUICK_FIX: Minor issues we can fix locally (no Aristotle needed)
- RETRY: Previously failed, needs retry
"""

import json
import os
import re
import subprocess
import sys
import time
from pathlib import Path
from typing import Dict, List, Tuple, Optional

PROJECT_ROOT = Path(__file__).parent.parent
TAXCODE_DIR = PROJECT_ROOT / "src" / "TaxCode"
QUEUE_FILE = PROJECT_ROOT / "data" / "aristotle_queue.json"
RERUN_QUEUE_FILE = PROJECT_ROOT / "data" / "aristotle_rerun_queue.json"
TRIAGE_FILE = PROJECT_ROOT / "data" / "triage_results.json"

# Priority weights for sections (lower = higher priority)
PRIORITY_TIERS = {
    # Core income definitions (highest priority)
    range(61, 91): 1,
    # Deductions
    range(161, 200): 2,
    # Credits
    range(21, 55): 3,
    # Exemptions
    range(101, 140): 4,
    # Capital gains
    range(1001, 1100): 5,
    # Corporate
    range(301, 400): 6,
    # Retirement
    range(401, 500): 7,
    # Estate/Gift
    range(2001, 3000): 8,
    # International (lowest priority)
    range(861, 1000): 9,
}

def get_priority(section_num: int) -> int:
    """Get priority tier for a section number."""
    for range_obj, priority in PRIORITY_TIERS.items():
        if section_num in range_obj:
            return priority
    return 10  # Default priority for unlisted sections


def load_queue_status() -> Dict[str, str]:
    """Load existing queue status."""
    status = {}

    if QUEUE_FILE.exists():
        with open(QUEUE_FILE) as f:
            data = json.load(f)
            for sec, info in data.get("sections", {}).items():
                status[sec] = info.get("status", "unknown")

    if RERUN_QUEUE_FILE.exists():
        with open(RERUN_QUEUE_FILE) as f:
            data = json.load(f)
            for sec, info in data.get("sections", {}).items():
                if info.get("status") == "failed":
                    status[sec] = "failed_retry"

    return status


def analyze_file(filepath: Path) -> Dict:
    """Analyze a single Lean file and categorize it."""
    content = filepath.read_text()
    filename = filepath.name

    # Extract section number
    match = re.match(r'Section(\d+)', filename)
    section_num = int(match.group(1)) if match else 0

    result = {
        "file": filename,
        "section": section_num,
        "priority": get_priority(section_num),
        "lines": len(content.split('\n')),
        "size_kb": len(content) / 1024,
    }

    # Check for stub patterns
    stub_patterns = [
        r'TODO: Add type definitions',
        r'TODO: Add main functions',
        r'TODO: Add theorems',
    ]
    stub_count = sum(1 for p in stub_patterns if re.search(p, content))

    # Check for sorry (incomplete proofs)
    sorry_count = len(re.findall(r'\bsorry\b', content))

    # Check for Aristotle header (generated file)
    has_aristotle = 'This file was generated by Aristotle' in content

    # Check for real implementation patterns
    has_structures = len(re.findall(r'structure\s+\w+', content)) > 0
    has_functions = len(re.findall(r'def\s+\w+', content)) > 2  # More than just Currency
    has_theorems = len(re.findall(r'theorem\s+\w+', content)) > 0
    has_proofs = 'by' in content or 'Proof' in content

    # Check for compilation issues
    has_placeholder = '#check placeholder' in content
    has_eval_only = re.search(r"#eval\s+['\"]Section", content) is not None

    # Categorize
    if stub_count >= 2 or (not has_functions and not has_theorems):
        result["category"] = "STUB"
        result["reason"] = f"Has {stub_count} TODO markers, no real implementation"
    elif has_placeholder:
        result["category"] = "QUICK_FIX"
        result["reason"] = "Has #check placeholder - can remove locally"
    elif sorry_count > 0:
        result["category"] = "SORRY"
        result["reason"] = f"Has {sorry_count} sorry markers - needs proof completion"
        result["sorry_count"] = sorry_count
    elif has_aristotle and has_functions and has_theorems:
        if sorry_count == 0:
            result["category"] = "COMPLETE"
            result["reason"] = "Aristotle-generated with proofs"
        else:
            result["category"] = "SORRY"
            result["reason"] = f"Aristotle-generated but has {sorry_count} incomplete proofs"
    elif has_functions and has_theorems and has_proofs:
        result["category"] = "COMPLETE"
        result["reason"] = "Has implementation and proofs"
    elif has_functions and not has_theorems:
        result["category"] = "NEEDS_THEOREMS"
        result["reason"] = "Has functions but no theorems"
    else:
        result["category"] = "REVIEW"
        result["reason"] = "Ambiguous - needs Grok review"
        result["has_structures"] = has_structures
        result["has_functions"] = has_functions
        result["has_theorems"] = has_theorems

    return result


def grok_review(files_to_review: List[Dict]) -> List[Dict]:
    """Use Grok API to review ambiguous files."""
    if not files_to_review:
        return []

    api_key = os.environ.get("GROK_API_KEY")
    if not api_key:
        print("WARNING: GROK_API_KEY not set, skipping Grok review")
        return files_to_review

    print(f"\nReviewing {len(files_to_review)} ambiguous files with Grok...")

    reviewed = []
    for item in files_to_review:
        filepath = TAXCODE_DIR / item["file"]
        content = filepath.read_text()

        # Truncate if too long
        if len(content) > 4000:
            content = content[:4000] + "\n... (truncated)"

        prompt = f"""Analyze this Lean 4 tax code formalization file and determine the best action:

FILE: {item['file']}
CONTENT:
```lean
{content}
```

Respond with EXACTLY ONE of these categories and a brief reason:
1. COMPLETE - File has real implementation and complete proofs, no action needed
2. SORRY - File has implementation but contains 'sorry' that needs Aristotle proof completion
3. STUB - File is mostly empty/boilerplate, needs full Aristotle formalization
4. QUICK_FIX - Has minor issues (like undefined placeholders) we can fix with simple edits

Format: CATEGORY: reason"""

        try:
            request = {
                "messages": [{"role": "user", "content": prompt}],
                "model": "grok-4",
                "temperature": 0,
                "max_tokens": 200
            }

            with open("/tmp/grok_triage_req.json", "w") as f:
                json.dump(request, f)

            result = subprocess.run(
                ["curl", "-s", "-X", "POST", "https://api.x.ai/v1/chat/completions",
                 "-H", f"Authorization: Bearer {api_key}",
                 "-H", "Content-Type: application/json",
                 "-d", "@/tmp/grok_triage_req.json"],
                capture_output=True,
                text=True,
                timeout=60
            )

            response = json.loads(result.stdout)
            answer = response.get("choices", [{}])[0].get("message", {}).get("content", "")

            # Parse response
            if "COMPLETE" in answer:
                item["category"] = "COMPLETE"
            elif "SORRY" in answer:
                item["category"] = "SORRY"
            elif "STUB" in answer:
                item["category"] = "STUB"
            elif "QUICK_FIX" in answer:
                item["category"] = "QUICK_FIX"

            item["grok_review"] = answer.strip()
            print(f"  {item['file']}: {item['category']}")

            time.sleep(1)  # Rate limit

        except Exception as e:
            print(f"  {item['file']}: Error - {e}")
            item["category"] = "REVIEW"
            item["error"] = str(e)

        reviewed.append(item)

    return reviewed


def run_triage(max_grok_reviews: int = 20):
    """Run full triage on all section files."""
    print("="*60)
    print("GROK-ASSISTED TRIAGE SYSTEM")
    print("="*60)

    # Load existing queue status
    queue_status = load_queue_status()
    print(f"\nLoaded queue status for {len(queue_status)} sections")

    # Get all section files
    files = sorted(TAXCODE_DIR.glob("Section*.lean"))
    # Exclude _aristotle variants
    files = [f for f in files if "_aristotle" not in f.name]
    print(f"Found {len(files)} section files to analyze")

    # Analyze all files
    print("\nPhase 1: Auto-categorizing files...")
    results = []
    for f in files:
        result = analyze_file(f)

        # Check if it's a known failed retry
        sec_str = str(result["section"])
        if sec_str in queue_status:
            if queue_status[sec_str] == "failed_retry":
                result["category"] = "RETRY"
                result["reason"] = "Previously failed, needs retry"
            elif queue_status[sec_str] == "complete":
                if result["category"] not in ["SORRY"]:  # Don't override if has sorry
                    result["category"] = "COMPLETE"
                    result["reason"] = "Marked complete in queue"

        results.append(result)

    # Count categories
    categories = {}
    for r in results:
        cat = r["category"]
        if cat not in categories:
            categories[cat] = []
        categories[cat].append(r)

    print("\nPhase 1 Results:")
    for cat, items in sorted(categories.items()):
        print(f"  {cat}: {len(items)}")

    # Review ambiguous files with Grok
    to_review = categories.get("REVIEW", [])[:max_grok_reviews]
    if to_review:
        print(f"\nPhase 2: Grok reviewing {len(to_review)} ambiguous files...")
        reviewed = grok_review(to_review)

        # Update results
        reviewed_files = {r["file"] for r in reviewed}
        results = [r for r in results if r["file"] not in reviewed_files] + reviewed

    # Re-count after Grok review
    categories = {}
    for r in results:
        cat = r["category"]
        if cat not in categories:
            categories[cat] = []
        categories[cat].append(r)

    print("\n" + "="*60)
    print("FINAL TRIAGE RESULTS")
    print("="*60)
    for cat, items in sorted(categories.items()):
        print(f"\n{cat}: {len(items)} files")
        if cat in ["RETRY", "QUICK_FIX", "SORRY"] and len(items) <= 15:
            for item in sorted(items, key=lambda x: x["priority"]):
                print(f"  - Section{item['section']}: {item.get('reason', '')}")

    # Save results
    triage_data = {
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "summary": {cat: len(items) for cat, items in categories.items()},
        "files": results,
        "categories": {cat: [r["file"] for r in items] for cat, items in categories.items()}
    }

    with open(TRIAGE_FILE, "w") as f:
        json.dump(triage_data, f, indent=2)

    print(f"\nResults saved to: {TRIAGE_FILE}")

    # Generate resubmission queue
    print("\n" + "="*60)
    print("RESUBMISSION QUEUE")
    print("="*60)

    queue = []

    # Priority 1: RETRY (previously failed)
    for item in categories.get("RETRY", []):
        queue.append({"section": item["section"], "action": "retry", "priority": 0})

    # Priority 2: SORRY (need proof completion)
    for item in sorted(categories.get("SORRY", []), key=lambda x: x["priority"]):
        queue.append({"section": item["section"], "action": "proof_complete", "priority": 1})

    # Priority 3: STUB (need full formalization) - by tier
    for item in sorted(categories.get("STUB", []), key=lambda x: (x["priority"], x["section"])):
        queue.append({"section": item["section"], "action": "formalize", "priority": item["priority"]})

    print(f"\nQueue built with {len(queue)} items:")
    print(f"  - Retries: {len(categories.get('RETRY', []))}")
    print(f"  - Proof completions: {len(categories.get('SORRY', []))}")
    print(f"  - Full formalizations: {len(categories.get('STUB', []))}")

    # Save queue
    queue_data = {
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "queue": queue,
        "quick_fixes": categories.get("QUICK_FIX", [])
    }

    queue_file = PROJECT_ROOT / "data" / "formalization_queue.json"
    with open(queue_file, "w") as f:
        json.dump(queue_data, f, indent=2)

    print(f"Queue saved to: {queue_file}")

    return triage_data, queue_data


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Grok-assisted triage for Aristotle resubmissions")
    parser.add_argument("--max-grok", type=int, default=20,
                        help="Max files to review with Grok API")
    parser.add_argument("--no-grok", action="store_true",
                        help="Skip Grok review entirely")
    args = parser.parse_args()

    max_reviews = 0 if args.no_grok else args.max_grok
    run_triage(max_grok_reviews=max_reviews)
